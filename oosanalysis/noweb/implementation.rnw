\documentclass[11pt]{article}
\usepackage{noweb,setspace,amsmath,amsthm,amssymb,microtype,ragged2e}
\usepackage[round]{natbib}
\usepackage[margin = 1in]{geometry}
\usepackage{hyperref}
\frenchspacing
\DeclareMicrotypeAlias{cmor}{cmr}
\DisableLigatures{family=tt*}
\noweboptions{longxref}
\def\nwendcode{\endtrivlist \endgroup}
\let\nwdocspar=\par
\bibliographystyle{abbrvnat}
\newcommand\citepos[2][]{\citeauthor{#2}'s \citeyearpar[#1]{#2}}

\newcommand{\dmw}{\textsc{dmw}}
\newcommand{\gnu}{\textsc{gnu}}
\newcommand{\mds}{\textsc{mds}}
\newcommand{\oos}{\textsc{oos}}

\renewcommand{\Re}{\ensuremath{\mathbb{R}}}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\WN}{WN}
\DeclareMathOperator{\E}{E}
\DeclareMathOperator{\var}{var}
\DeclareMathOperator{\N}{N}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\plim}{plim}
\DeclareMathOperator{\eig}{\lambda_{\max}}
\DeclareMathOperator{\eigl}{\lambda_{\min}}
\DeclareMathOperator{\p}{Pr}
\DeclareMathOperator{\ind}{1}


\begin{document}

\title{Implementation details: `oosanalysis'
  package\footnote{Copyright \textcopyright\ 2011 by Gray Calhoun
    \texttt{<gcalhoun@iastate.edu>.}}}

\author{Gray Calhoun\\Iowa State University} \date{Version 0.2.1\\\today}

\maketitle

\tableofcontents

\section{Out-of-sample comparisons}

This section describes the code for the actual test statistics.

\subsection{Diebold-Mariano-West test statistic}
Probably the most important of the \oos\ statistics is the
Diebold-Mariano-West test \citep{DiM:95,Wes:96}.  For now, I've just
written up a bare-bones version of the statistic that requires the
user to explictly calculate \citepos{Wes:96} variables and pass them
to the function.  It would be convenient to write another function
that takes higher-level arguments, but I'm not sure that there's a
good general way to do that.  The function [[mixedwindow]] does
provide a higher-level function that then calls this function, so it
might be a good template if one wants to code up others.

The function [[dmw_calculation]] estimates the mean and variance of
the \oos\ process $f_{t}(\beta)$.  In \citet{WeM:98}, the recursive
window coefficient estimator can be written in the form
\begin{equation}
  \label{eq:1}
  \hat{\beta}_{t} = B_{t} \tfrac{1}{T} \sum_{s=1}^{t}
  h_{t}.\footnote{The notation for the recursive window is slightly
    different than \citet{Wes:96} uses.}
\end{equation}
Changing the formula for the fixed and rolling window estimators is
straightforward.  The asymptotic variance of the \oos\ average is
\begin{equation}
  \label{eq:2}
  S_{ff} + (S_{fh} B' F' + F B S_{fh}') \lambda_{fh} + \lambda_{hh}
  F B S_{hh} B' F'
\end{equation}
where $B = \plim B_{t}$, $F = \E \tfrac{\partial}{\partial \beta}
f_{t}(\beta)$, $S$ is the long-run variance of $(f_{t}, h_{t})$, and
$\lambda$ is a vector of scale factors that depend on the window used.

<<dmw.R>>=
dmw_calculation <- function(f, h, R, vcv, tBtF = NULL, 
                            window = c("recursive", "rolling", "fixed")) {
  noos <- length(f)
  lambda <- dmw_lambda(pi = noos / R, window)
  htBtF <- if (is.null(tBtF)) {
    rep(0, noos) 
  } else {
    tcrossprod(as.matrix(h), matrix(tBtF, nrow = 1))
  }
  S <- vcv(cbind(f, htBtF))
  return(list(mu = mean(f), avar = S[1,1] + lambda$fh * (S[1,2] + S[2,1]) 
                                   + lambda$hh * S[2,2]))
}
@ %def dmw_calculation

The function [[dmw_lambda]] calculates the scale terms used to
calculate the asymptotic covariance matrix of the \oos\ average, $\bar
f$.  \citet{Wes:96} derives the formula for the recursive window and
\citet{WeM:98} for the rolling and fixed windows.
<<dmw.R>>=
dmw_lambda <- function(pi, window = c("recursive", "rolling", "fixed")) {
  window <- match.arg(window)
  if (window == "recursive") {
    lambda.fh <- 1 - log(1 + pi)/pi
    lambda.hh <- 2 * lambda.fh
  } else if (window == "fixed") {
    lambda.fh <- 0
    lambda.hh <- pi
  } else if (window == "rolling" && pi <= 1) {
    lambda.fh <- pi/2
    lambda.hh <- pi - pi^2 / 3
  } else if (window == "rolling" && pi > 1) {
    lambda.fh <- 1 - 1/(2*pi)
    lambda.hh <- 1 - 1/(3*pi)
  }
  return(list(fh = lambda.fh, hh = lambda.hh))
}
@ %def dmw_lambda

\subsection{Clark and West (2006, 2007) test statistic}
The next statisic is developed in \citet{ClW:06,ClW:07}, who propose
using a fixed-length rolling window to get an asymptotically normal
statistic \citep[as in][]{Giw:06}, but add a correction to the \oos\
average so that it's centered correctly for testing the null that the
benchmark is an \mds.  I implement it as two functions.  One to
estimate the \oos\ forecasts for given data and models.  And one to
construct the statistic.

<<clarkwest.R>>=
clarkwest <- function(null, alt, dataset, R, vcv = var,
                      window = c("rolling", "recursive", "fixed"))
  clarkwest_calculation(
    target        = extract_target(null, dataset[-seq_len(R),,drop = FALSE]),
    null.forecast = recursive_forecasts(null, dataset, R, window),
    alt.forecast  = recursive_forecasts(alt, dataset, R, window),
    vcv)
@ %def clarkwest

<<clarkwest.R>>=
clarkwest_calculation <- function(target, null.forecast, 
                                  alt.forecast, vcv) {
  P <- length(target)
  oos.sequence <- {(target - null.forecast)^2 - 
                   (target - alt.forecast)^2 + 
                   (null.forecast - alt.forecast)^2}
  mu <- mean(oos.sequence)
  avar <- vcv(oos.sequence)
  return(list(mu = mu, avar = avar, 
              pvalue = pnorm(sqrt(P) * mu, 0, sqrt(avar), FALSE)))
}
@ %def clarkwest_calculation

\subsection{Mixed window test statistics}

This subsection implements the statistic proposed by \citet{Cal:11b}.
This statistic uses a recursive window for the benchmark and a
fixed-length rolling or fixed window for the alternative.  The
function [[mixedwindow]] is basically a wrapper for
[[mixedwindow_calculation]].
<<mixedwindow.R>>=
mixedwindow <- function(null, alt, dataset, R, vcv = var,
                        window = c("rolling", "fixed")) {
  nobs <- nrow(dataset)
  estimates <-
    mixedwindow_calculation(y = extract_target(null, dataset),
                            X = extract_predictors(null, dataset),
                            recursive_forecasts(null, dataset, R, "recursive"),
                            recursive_forecasts(alt, dataset, R, window),
                            vcv = vcv)
  estimates$tstat <- with(estimates, mu * sqrt((nobs - R) / avar))
  estimates$pvalue <- pnorm(estimates$tstat, lower.tail = FALSE)
  return(estimates)
}
@ [[mixedwindow_calculation]] constructs the \oos\ processes and then %def mixedwindow
them to the [[dmw_calculation]] function to generate the
final statistics.  It might seem a little silly to have
[[mixedwindow]] and [[mixedwindow_calculation]] as distinct functions,
but we reuse [[mixedwindow_calculation]] in the bootstrap.

<<mixedwindow.R>>=
mixedwindow_calculation <- function(y, X, forecasts.null, forecasts.alt, vcv) {
  X <- as.matrix(X)
  nobs <- length(y)
  noos <- length(forecasts.null)
  oos <- seq.int(to = nobs, length = noos)
  errors.null <- y[oos] - forecasts.null
  errors.alt  <- y[oos] - forecasts.alt
  forecast.differences <- forecasts.null - forecasts.alt
  dmw_calculation(f = errors.null^2 - errors.alt^2 + forecast.differences^2,
                  h = errors.null * X[oos,,drop = FALSE],
                  R = nobs - noos, vcv = vcv,
                  tBtF = 2 * solve(crossprod(X) / nobs, 
                           colMeans((forecast.differences -
                                     errors.null) * X[oos,,drop=FALSE])),
                  window = "recursive")
}
@ %def mixedwindow_calculation

The [[mixedbootstrap]] function uses [[mixedwindow_calculation]] to
implement \citepos{Cal:11b} bootstrap.  I implement the bootstrap by
generating random indices rather than actually randomizing the data,
since we have several distinct sequences that we need to bootstrap
jointly (I assume that this is the usual way people do it).  The local
function [[rbootindex]] takes no arguments, but is defined to generate
a length [[nobs]] vector with blocks of length [[blocklength]] that
induces the moving blocks \citep{Kun:89,LiS:92} or circular blocks
\citep{PoR:92} bootstraps.  
The [[extendedindex]] vector automatically
includes the first [[R]] observations so that the bootstrap population
mean is equal to the sample mean of the data (for the circular blocks
bootstrap).
<<mixedwindow.R>>=
mixedbootstrap <- function(null, alt.list, dataset, R, nboot, blocklength,
                           vcv = var, window = c("rolling", "fixed"),
                           bootstrap = c("moving", "circular")) {
  <<define [[mixedbootstrap]] local variables>>
  <<define block bootstrap function [[rbootindex]]>>
  replicate(nboot, {
    bootindex <- rbootindex()
    extendedindex <- c(seq_len(R), R + bootindex)
    sapply(forecasts.alt, function(alt) {
      mixedwindow_calculation(y[extendedindex], X[extendedindex,,drop=FALSE],
                              recursive_forecasts(null,
                                dataset[extendedindex,], R, "recursive"),
                              alt[bootindex], vcv)$tstat
  })})
}
@ %def mixedbootstrap
One nice feature of this bootstrap is that it's only necessary to
reestimate the benchmark model.  The alternative models are estimated
once, and their forecasts are resampled along with the original data.
The first step in the function is to define local variables and
generate these forecasts.
<<define [[mixedbootstrap]] local variables>>=
nobs <- nrow(dataset)
noos <- nobs - R
window <- match.arg(window)
bootstrap <- match.arg(bootstrap)
X <- extract_predictors(null, dataset)
y <- extract_target(null, dataset)
forecasts.alt <- lapply(alt.list, function(m) {
  recursive_forecasts(m, dataset, R, window)
})
@ 

The next two functions generate indices that induce the moving blocks
bootstrap or circular blocks bootstrap.  I prefer to have these as
separate fuctions rather than as a single function that takes the
bootstrap type as an argument.  I don't really see a reason to repeat
the logical operation to determine the bootstrap type every time we
want to generate a new bootstrap sample.  It seems like that
operation should be done only once (I realize that the time savings
are basically zero compared to the time it takes to do the estimation,
but still\dots).
<<bootindex.R>>=
bootindex_movingblock <- function(nobs, blocklength) {
  blockstarts <- sample(seq_len(nobs - blocklength + 1),
                        ceiling(nobs / blocklength))
  as.vector(sapply(blockstarts, function(s) s:(s + blocklength - 1)))[1:nobs]
}

bootindex_circularblock <- function(nobs, blocklength) {
  blockstarts <- sample(seq_len(nobs), ceiling(nobs / blocklength))
  as.vector(sapply(blockstarts, function(s)
                   (s + seq_len(blocklength) - 1) %% nobs + 1))[seq_len(nobs)]
}
@ %def bootindex_movingblock bootindex_circularblock

[[rbootindex]] just chooses between the two boostrap functions
depending on the argument passed to [[mixedbootstrap]].
<<define block bootstrap function [[rbootindex]]>>=  
rbootindex <- switch(bootstrap,
  moving = function() bootindex_movingblock(noos, blocklength),
  circular = function() bootindex_circularblock(noos, blocklength))
@ %def rbootindex


\section{Other functions}
\subsection{StepM (Romano and Wolf, 2005)} 

[[stepm]] implements \citepos{RoW:05} stepdown procedure to test
multiple models.
<<stepm.R>>=
stepm <- function(teststatistics, bootmatrix, level) {
  nstatistics <- length(teststatistics)
  rejected <- rep(FALSE, nstatistics)
  nrejected.endofloop <- 0
  repeat {
    nrejected.topofloop <- nrejected.endofloop
    criticalvalue <- quantile(apply(bootmatrix[!rejected,,drop=FALSE],
                                    2, max), 1 - level)
    rejected[teststatistics > criticalvalue] <- TRUE
    nrejected.endofloop <- sum(rejected)
    if (nrejected.endofloop == nrejected.topofloop ||
        nrejected.endofloop >= nstatistics) break
  }
  return(list(criticalvalue = criticalvalue, rejected = rejected))
}
@ %def stepm

\subsection{Forecast estimation}

The [[recursive_forecasts]] function constructs a sequence of rolling,
recursive, or fixed window forecasts using [[model]].  [[model]] must
be a function that takes subsets of [[dataset]] as an argument and
returns an object with a [[predict]] method.
<<recursive-forecasts.R>>=
recursive_forecasts <- function(model, dataset, R,
                         window = c("recursive", "rolling", "fixed"),...) {
  window <- match.arg(window)
  n <- nrow(dataset)
  if (R >= n) stop("dataset must have more than R observations")
  getprediction <- function(firstobs, lastobs, horizon)
    predict(model(dataset[seq(firstobs, lastobs, by = 1),],...),
            newdata = dataset[lastobs + horizon,])
  switch(window,
         recursive = sapply((R+1):n, function(s) getprediction(1, s-1, 1)),
         rolling   = sapply((R+1):n, function(s) getprediction(s-R, s-1, 1)),
         fixed     = getprediction(1, R, 1:(n-R)))
}                 
@ %def recursive_forecasts

\subsection{Model manipulation}

[[extract_target]] and [[extract_predictors]] are designed to take the
[[model]] and [[dataset]] arguments that are passed to functions like
[[mixedwindow]] and return either the predictand or the predictors
for the [[null]] model.  These quantities are then used to approximate
the distribution of the \oos\ average.
<<extract.R>>=
extract_predictors <- function(model, dataset)
  model.matrix(terms(model(dataset[1,])), data = dataset)

extract_target <- function(model, dataset) {
  target <- model.response(model.frame(terms(model(dataset[1,])), dataset))
  if (is.ts(dataset))
    target <- ts(target, start = start(dataset), frequency = frequency(dataset))
  target
}
@ %def extract_predictors extract_target

\appendix

\section{Namespace}
The [[NAMESPACE]] file specifies which of the functions defined in
this package are meant to be accessible to the users (among other things).

<<NAMESPACE>>=
export(clarkwest, mixedwindow, mixedbootstrap, recursive_forecasts, stepm,
       dmw_calculation, bootindex_circularblock, bootindex_movingblock,
       extract_target, extract_predictors)
@

\section{Licensing information for this software}

This program is free software: you can redistribute it and/or modify
it under the terms of the \gnu\ General Public License as published by
the Free Software Foundation, either version 3 of the License, or (at
your option) any later version.

This program is distributed in the hope that it will be useful, but
\textsc{without any warranty}; without even the implied warranty of
\textsc{merchantability} or \textsc{fitness for a particular purpose}.
See the \gnu\ General Public License for more details.

You should have received a copy of the \gnu\ General Public License
along with this program.  If not, see
\texttt{<http://www.gnu.org/licenses/>}.

\bibliography{AllRefs}
\addcontentsline{toc}{section}{References}

\section*{Index}
\addcontentsline{toc}{section}{Index}

\subsection*{Functions and variables}
\addcontentsline{toc}{subsection}{Functions and variables}
\nowebindex

\subsection*{Code chunks}
\addcontentsline{toc}{subsection}{Code chunks}
\nowebchunks

\end{document}

% LocalWords:  mixedwindow dmw mixedbootstrap rbootindex blocklength stepm
% LocalWords:  extendedindex NAMESPACE clarkwest bootindex
