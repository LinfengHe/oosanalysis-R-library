\documentclass{article}
\usepackage{noweb,setspace,amsmath,amsthm,amssymb,microtype}
\usepackage[round]{natbib}
\bibliographystyle{abbrvnat}
\frenchspacing

% These next two lines make latex more willing to break code chunks
% across pages:
\def\nwendcode{\endtrivlist \endgroup}
\let\nwdocspar=\par

\renewcommand{\Re}{\ensuremath{\mathbb{R}}}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\WN}{WN}
\DeclareMathOperator{\E}{E}
\DeclareMathOperator{\var}{var}
\DeclareMathOperator{\N}{N}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\plim}{plim}
\DeclareMathOperator{\eig}{\lambda_{\max}}
\DeclareMathOperator{\eigl}{\lambda_{\min}}
\DeclareMathOperator{\p}{Pr}
\DeclareMathOperator{\ind}{1}


\begin{document}

\title{Implementation details: Functions to compare forecasting models out-of-sample}
\author{Gray Calhoun\\Iowa State University} \date{\today}

\maketitle
\tableofcontents

Some introductory text

\section{Main functions?}
<<forecast.error.R>>=
forecast.error <- function(object, newdata,...) {
  if (missing(newdata) || is.null(newdata)) {
    stop("must supply 'newdata'")
  }
  ## If 'newdata' is a ts object, we need to make sure that dynamic
  ## models don't mess up the indexing
  tt <- terms(object)
  Y.new <- model.response(model.frame(tt, newdata))
  if (is.ts(newdata)) {
    Y.new <- ts(Y.new, start = start(newdata),
                frequency = frequency(newdata))
  }
  Y.hat <- predict(object, newdata,...)
  unname(Y.new - Y.hat)
}
@

<<apply.oos.R>>=
apply.oos <- function(R, d, model,
                      window = c("rolling", "recursive", "fixed"),
                      ret = c("forecast", "error"),...) {
  window <- match.arg(window)
  ret <- match.arg(ret)
  n <- nobs(d)
  d <- as.ts(d)
  p <- time(d)
  predfn <- switch(ret, forecast = predict, error = forecast.error)
  ## note that in all of the switch statements, we're going to let
  ## 'newdata' include the training sample, and then just take the
  ## last forecast or forecast error.  This is so that dynamic models
  ## can get their regressors from the training sample.  For the same
  ## reason, we make everything a time series and use windows, instead
  ## of subsetting (for some reason, time series objects lose their
  ## time series properties after subsetting, which is kind of
  ## annoying).
  ## 
  ## Note that the "predict" methods are kind of crappy, in that they
  ## return a vector of the same length as "newdata" has observations,
  ## even when some of the observations are lost to lag strucutre,
  ## etc.
  ##
  ## As you can imagine, this code is *extremely* slow.
  lastPred <- function(startEst, endEst, s,
                       m = model(window(d, start = p[startEst], end = p[endEst]),
                         ...),...) {
    predictions <- predfn(m, newdata = window(d, start = p[startEst], end = p[s]))
    if (is.ts(predictions)) {
      window(predictions, start = p[s], end = p[s])
    } else {
      tail(predictions, 1)
    }
  }
  
  ts(unname(switch(window,
                   recursive = sapply((R+1):n, function(s) lastPred(1, s-1, s,...)),
                   rolling =   sapply((R+1):n, function(s) lastPred(s-R, s-1, s,...)),
                   fixed = {
                     m <- model(window(d, end = p[R]),...)
                     sapply((R+1):n, function(s) lastPred(1, R, s, m))
                   })), end = end(d), frequency = frequency(d))
}
@

<<oos.t.R>>=
newhtest <- function(...) {
  x <- list()
  buildhtest(x) <- list(...)
  x
}

## a more general version of 'names', just reflecting the fact that
## confidence intervals aren't stored as "names" for some reason.
hNames <- function(x, elem = "") {
  if (elem == "conf.int") {
    attr(x, "conf.level")
  } else {
    names(x)
  }
}

'hNames<-' <- function(x, elem = "", value) {
  if (elem == "conf.int") {
    attr(x, "conf.level") <- value
  } else {
    names(x) <- value
  }
  x
}

'buildhtest<-' <- function(x, value) {
  ## an htest is a list (with class htest) and the following elements:
  ## 'null.value' (with name 'null.text')
  ## 'parameter'  (with name 'parameter.text')
  ## 'method'
  ## 'data.name'
  ## 'alternative'
  ## 'estimate'   (with name 'estimate.text')
  ## 'statistic'  (with name 'statistic.text')
  ## 'p.value'
  ## 'conf.int'   (with attribute 'conf.level')
    
  'positionText<-' <- function(x, value) {
    elem <- value[1]
    elem.text <- value[2]
    xnames <- names(x)
    ielem <- which(xnames == elem)
    nelem <- sum(ielem)
    if (nelem >= 2) {
      ## we're replacing the 'elem' entry; we just need to make sure
      ## that we keep the names from the existing entry
      if (is.null(hNames(x[[max(ielem)]], elem))) {
        hNames(x[[tail(ielem, 1)]], elem) <- hNames(x[[min(ielem)]], elem)
      }
      x[head(ielem, -1)] <- NULL
    }
    if (elem.text %in% xnames) {
      ## if 'elem' is missing, add it with value NA.
      if (nelem == 0) {
        x <- c(x, list(NA))
        names(x) <- c(xnames, elem)
      }
      hNames(x[[elem]], elem) <- x[[elem.text]]
      x[[elem.text]] <- NULL
    }
    x
  }
  
  x <- c(as.list(x), as.list(value))
  positionText(x) <- c("parameter", "parameter.text")
  positionText(x) <- c("null.value", "null.text")
  positionText(x) <- c("estimate", "estimate.text")
  positionText(x) <- c("statistic", "statistic.text")
  positionText(x) <- c("conf.int", "conf.level")
  class(x) <- "htest"
  x
}

lossDiff <- function(null.model, alt.model, data, R, window,
                     L = function(x) x^2, return.forecasts = FALSE,
                     return.errors = FALSE) {

  if (is.null(names(alt.model)))
    names(alt.model) <- paste("alt", seq_along(alt.model), sep = ".")
  
  errors <- lapply(alt.model, function(m)
                   apply.oos(R, data, m, window, "error"))
  loss <- lapply(errors, L)

  ## if null.model is given, we want to return the difference in the
  ## loss of the two models, and (potentially) the forecasts
  ## associated with each model.
  if (!is.null(null.model)) {
    errors <- c(list("null" = apply.oos(R, data, null.model, window, "error")),
                errors)
    null.model <- list("null" = null.model)
    null.loss <- L(errors[[1]])
    loss <- lapply(loss, function(l) null.loss - l)
  }

  if (return.errors)
    attr(loss, "error") <- errors
  if (return.forecasts)
    attr(loss, "forecast") <-
      lapply(c(null.model, alt.model), function(m)
             apply.oos(R, data, m, window, "forecast"))
  loss
}

dFull <- function(data1, data2) {
  if (is.ts(data1)) {
    freq <- frequency(data1)
    s1 <- time(data1)[1]
    f1 <- tail(time(data1), 1)
    if (is.ts(data2)) {
      s2 <- time(data2)[1]
      f2 <- tail(time(data2), 1)
    } else {
      s2 <- tail(time(lag(data1, -1)), 1)
      f2 <- tail(time(lag(data1, -nobs(data2))), 1)
    }
  } else if (is.ts(data2)) {
    freq <- frequency(data2)
    s2 <- time(data2)[1]
    f2 <- tail(time(data2), 1)
    s1 <- time(lag(data2, nobs(data1)))[1]
    f1 <- time(lag(data2, 1))[1]
  } else {
    data1[,setdiff(names(data2), names(data1))] <- NA
    data2[,setdiff(names(data1), names(data2))] <- NA
    return(rbind(data1, data2))
  }
  ## this is a pretty crappy way to assemble the time series matrix;
  cols <- union(colnames(data1), colnames(data2))
  m <- ts(matrix(NA, nobs(data1) + nobs(data2), length(cols)),
          start = s1, end = f2, frequency = freq)
  colnames(m) <- cols
  for (cd in colnames(data1)) 
    window(m[, cd], start = s1, end = f1) <- data1[, cd]
  for (cd in colnames(data2))
    window(m[, cd], start = s2, end = f2) <- data2[, cd]
  m
}

oos.t <- function(null.model, alt.model, data, R, L = function(x) x^2,
                  window = c("recursive", "rolling", "fixed"),
                  method = c("DMW", "ClW:07", "Mcc:07", "Cal:11"),
                  alternative = "greater", conf.level = 0.95,
                  return.forecasts = FALSE, return.errors = FALSE) {
  
  method <- match.arg(method)
  window <- match.arg(window)
  if (method %in% c("ClW:07", "Mcc:07")) {
    if (alternative != "greater") {
      warning("Setting alternative to 'greater'")
      alternative <- "greater"
    }
    if (!identical(L, function(x) x^2)) {
      warning("Setting loss to MSE")
      L <- function(x) x^2
    }
  }
  returnList <- is.list(alt.model)
  if (!returnList) alt.model <- list(alt = alt.model)
  if (R >= nobs(data)) stop("'R' is larger than the dataset")

  if (method %in% c("ClW:07", "Cal:11")) {
    if (method == "ClW:07") {
      forecasts <- lapply(c(list(null = null.model), alt.model), function(m)
                          apply.oos(R, data, m, window, "forecast"))
      errors <-  lapply(c(list(null = null.model), alt.model), function(m)
                        apply.oos(R, data, m, window, "error"))
    } else {
      ## The difference between this method and the Clark-West method
      ## is that here the null is estimated using the recursive window
      ## and the alternative models are estimated with rolling windows.
      forecasts <- c(list(null = apply.oos(R, data, null.model, "recursive", "forecast")),
                     lapply(alt.model, function(m)
                            apply.oos(R, data, m, "rolling", "forecast")))
      errors <- c(list(null = apply.oos(R, data, null.model, "recursive", "error")),
                  lapply(alt.model, function(m)
                         apply.oos(R, data, m, "rolling", "error")))
    }
    P <- length(forecasts[[1]])

    oosObs <-
      lapply(seq_along(alt.model), function(i)
             errors[[1]]^2 - errors[[i+1]]^2
             + (forecasts[[1]] - forecasts[[i+1]])^2)
    ## do the one-sample test
    tstats <- lapply(oosObs, function(f) {
      favg <- mean(f)
      fstd <- sd(f) / sqrt(P)
      tstat <- favg / fstd
      newhtest(estimate = favg, estimate.text = "OOS Avg 1",
               statistic = tstat, parameter = c(R, P),
               p.value = pt(tstat, df = P-1, lower.tail = FALSE),
               conf.int = c(favg - fstd * qt(conf.level, df = P-1), Inf),
               method.text = sprintf("One-sample OOS t-test, %s window (%s)",
                 window, method))
    })
  } else {
    ## Use oos.t2 to calculate the statistic for the DMW and Mcc:07
    ## methods.
    tstats <- oos.t2(null.model, alt.model, data, R = R, P2 = Inf,
                     L = L, window = window, method = method,
                     alternative = alternative, conf.level = conf.level,
                     return.forecasts = return.forecasts,
                     return.errors = return.errors)
    ## replace the (R, P1, P2) notation with (R, P)
    lapply(tstats, function(tst) {
      buildhtest(tst) <-
        list(parameter = c(tst$parameter["R"], tst$parameter["P1"]))
      tst
    })
  }
  ## add the remaining information needed for the 'htest' object.
  tstats <- lapply(tstats, function(tst) {
    buildhtest(tst) <-
      list(data.name = deparse(substitute(data)),
           null.value = "E(L.alt)", null.text = "E(L.alt)",
           alternative = alternative, statistic.text = "oos-t",
           conf.level = conf.level, parameter.text = c("R", "P"),
           estimate.text = "OOS Avg")
    tst
  })
  if (returnList) tstats else tstats[[1]]
}

pval <- function(method = c("DMW", "Mcc:07"),
                 alternative = c("greater", "less", "two.sided"),
                 window = c("fixed", "recursive", "rolling"),
                 tstat, k, P1, P2, R) {
  method <- match.arg(method)
  alternative <- match.arg(alternative)
  pfn <- switch(method,
                DMW =      function(x,...) pt(x, df = P1-1,...),
                "Mcc:07" = function(x,...)
                  pmccracken.2(x, k, R, P1, P2, window,...))
  switch(alternative,
         greater   = pfn(tstat, lower.tail = FALSE),
         less      = pfn(tstat),
         two.sided = 1 + pfn(-abs(tstat)) - pfn(abs(tstat)))
}

cint <- function(method = c("DMW", "Mcc:07"),
                 alternative = c("greater", "less", "two.sided"),
                 window = c("fixed", "recursive", "rolling"),
                 avg, std, k, P1, P2, R, conf.level) {
  method <- match.arg(method)
  alternative <- match.arg(alternative)
  qfn <- switch(method,
                DMW =      function(x,...) qt(x, df = P1-1),
                "Mcc:07" = function(x,...)
                  qmccracken.2(x, k, R, P1, P2, window,...))
  switch(alternative,
         greater   = c(avg + std * qfn(1 - conf.level), Inf),
         less      = c(-Inf, avg + std * qfn(conf.level)),
         two.sided = avg + std * qfn(c(1 - conf.level, 1 + conf.level) / 2))
}           

## 'alternative' is the loss of the benchmark model relative to the
## alternative.  So the usual alternative is going to be that the loss
## of the null model is "greater" than that of the alternative.
oos.t2 <- function(null.model, alt.model, data, data2 = NULL,
                   R, P2 = nobs(data2), L = function(x) x^2,
                   window = c("rolling", "recursive", "fixed"),
                   method = c("DMW", "Mcc:07"), alternative = "greater",
                   conf.level = 0.95, return.forecasts = FALSE,
                   return.errors = FALSE) {

  window <- match.arg(window)
  returnList <- is.list(alt.model)
  if (!returnList) alt.model <- list(alt = alt.model)
  if (R >= nobs(data)) stop("'R' is larger than the dataset")

  method <- match.arg(method)
  if (is.null(null.model)) {
    k.null <- 0
    if (method != "DMW") {
      method <- "DMW"
      warning("We're setting method to 'DMW'. Without a null model, 'Mcc:07' doesn't make sense.")
    }
  } else {
    k.null <- ncol(model.matrix(null.model(data)))
  }
  
  ## start accumulating information for the 'htest' object
  tstats <-
    newhtest(data.name = deparse(substitute(data)),
             alternative = alternative, null.value = "Avg(L.alt)",
             null.text = "Avg(L.null)", statistic.text = "oos-t2",
             conf.level = conf.level)
  
  ## get the difference in loss over the first oos period
  ldiff1 <- lossDiff(null.model, alt.model, data, R, window, L,
                     return.forecasts, return.errors)
  P1 <- length(ldiff1[[1]])
  k.diff <- sapply(alt.model, function(alt) ncol(model.matrix(alt(data)))) - k.null
  ## estimate confidence interval for 2nd period oos average.  This is
  ## more opaque than I'd like; tstats is an htest that we started
  ## defining earlier; now we're going to replace it with a list of
  ## htests; one for each alternative model.  To do so, we're going to
  ## add the relevant attributes to the original we defined eariler.
  tstats <-
    lapply(seq_along(ldiff1), function(i) {
      lavg <- mean(ldiff1[[i]])
      lstd <- sd(ldiff1[[i]]) * sqrt(1/P1 + 1/P2)
      ## we're going to sneak in two extra elements, avg and std, to
      ## avoid recalculating them later.
      buildhtest(tstats) <-
        list(avg = lavg, std = lstd,
             conf.int = cint(method, alternative, window, lavg, lstd,
               k.diff[i], P1, P2, R, conf.level),
             parameter = c(R, P1, P2),
             parameter.text = c("R", "P1", "P2"))
      tstats
    })
  ## get the loss difference over the second OOS period if
  ## appropriate.  The '&&' is important (instead of '&') so that we
  ## don't evaluate nobs(data2) if data2 is NULL.
  if (!is.null(data2) && P2 <= nobs(data2)) {
    d2name <- deparse(substitute(data2))
    ## if data2 is supplied, we calculate the out-of-sample loss over
    ## the second oos period.  We have to handle the rolling window
    ## differently than the fixed or recursive window, since R doesn't
    ## change for the rolling window.  This is kind of a bitch
    ## notationally if you need to allow for dynamic models.
    data2 <- as.ts(dFull(data, data2[1:P2,]))
    if (window == "rolling") {
      data2 <- window(data2, start = time(data2)[nobs(data)-R+1])
      R2 <- R
    } else {
      R2 <- nobs(data)
    }
    ## calculate oos loss over the second sample
    ldiff2 <- lossDiff(null.model, alt.model, data2, R, window, L,
                       return.forecasts, return.errors)

    ## add the forecasts and errors to those for the first sample if
    ## requested.
    addTS <- function(name)
      lapply(seq_along(attr(ldiff1, name)), function(i)
             cts(attr(ldiff1, name)[[i]], attr(ldiff2, name)[[i]]))
    if (return.forecasts)
      attr(ldiff1, "forecast") <- addTS("forecast")
    if (return.errors)
      attr(ldiff1, "error") <- addTS("error")
    
    ## finalize the statistics for the two-sample case
    tstats <- lapply(seq_along(tstats), function(i) {
      tst <- tstats[[i]]
      lavg2 <- mean(ldiff2[[i]])
      stat <- (tst$avg - lavg2) / tst$std
      buildhtest(tst) <- 
        list(estimate = c(tst$avg, lavg2),
             estimate.text = c("OOS Avg 1", "OOS Avg 2"),
             statistic = stat,
             p.value = pval(method, alternative, window, stat, k.diff[i], P1, P2, R),             
             data.name = c(tstats$data.name, d2name),
             method.text = sprintf("Two-sample OOS t-test, %s window (%s)",
             window, method))
      tst[["avg"]] <- tst[["std"]] <- NULL
      tst
    })
  } else {
    ## calculate the p.value and remaining elements of each h-test for
    ## the one-sample test
    tstats <- lapply(seq_along(tstats), function(i) {
      tst <- tstats[[i]]
      stat <- tst$avg / tst$std
      buildhtest(tst) <- 
        list(estimate = tst$avg, estimate.text = "OOS Avg 1",
             statistic = stat,
             p.value = pval(method, alternative, window, stat, k.diff[i], P1, P2, R),
             method.text = sprintf("One-sample OOS t-test, %s window (%s)",
               window, method))
      tst[["avg"]] <- tst[["std"]] <- NULL
      tst                      
    })
  }

  if (!returnList) tstats <- tstats[[1]]
  if (return.errors) attr(tstats, "errors") <- attr(ldiff1, "error")
  if (return.forecasts) attr(tstats, "forecasts") <- attr(ldiff1, "forecast")
  tstats
}
@

\section{Utility functions}
<<lagmatrix.R>>=
lagmatrix <- function(x, L) {
  x <- as.ts(x)
  xmat <- do.call(cbind, lapply(seq(length = L), function(s) lag(x, -s)))
  if (!is.matrix(xmat)) dim(xmat) <- c(length(xmat), 1)
  if (is.null(colnames(x))) {
    colnames(xmat) <- rep(paste("L", 1:L, sep = ""),
                          each = ncol(x))
  } else {
    colnames(xmat) <- c(sapply(1:L, function(i)
                        paste(colnames(x), "L", i, sep = "")))
  }
  window(xmat, start = c(L,0)+start(x), end = end(x))
}
@

<<nobs.R>>=
setGeneric("nobs", function(x,...) standardGeneric("nobs"))
setMethod("nobs", "data.frame", function(x) nrow(x))
setMethod("nobs", "zoo", function(x) nrow(x))
setMethod("nobs", "mts", function(x) nrow(x))
setMethod("nobs", "matrix", function(x) nrow(x))
@

<<tr.R>>=
tr <- function(M) sum(diag(M))
@

<<cts.R>>=
cts <- function(x, y) {
  x <- as.ts(x)
  y <- as.ts(y)
  freq <- frequency(x)
  if (freq != frequency(y)) stop("both x and y must have the same frequency")
  ts(unname(c(x, y)), start = start(x), end = end(y), frequency = freq)
}
@

\section{Namespace}
<<NAMESPACE>>=
export(apply.oos, nobs, forecast.error, oos.t, oos.t2, critMcc1, critMcc2)
@

\bibliography{AllRefs}
\end{document}
